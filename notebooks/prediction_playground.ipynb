{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35cab72f-35c9-48cd-9fc0-76b0c18d422c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.transforms import Compose, Normalize, Resize, InterpolationMode\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from eval import evaluate, bootstrap, plot_roc\n",
    "from zero_shot import make as val_make, CXRTestDataset, make_true_labels, run_softmax_eval\n",
    "from run_train_multi import make as train_make\n",
    "from run_train import train_batch, train_log, save\n",
    "from train import preprocess_text\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4f1619b-e15d-4aa8-a93f-82042c12f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, initial_data):\n",
    "        for key in initial_data:\n",
    "            setattr(self, key, initial_data[key])\n",
    "            \n",
    "config = {\n",
    "    'train_cxr_folder': '../data/mimic-cxr-data/h5files/train-smoke-test/',\n",
    "    'train_txt_folder': '../data/mimic-cxr-data/reports/train-smoke-test/',\n",
    "    'val_cxr_filepath': '../data/chexpert-test/chexpert-test/chexlocalize/CheXpert/chexpert_test.h5',\n",
    "    'val_groundtruth': '../data/chexpert-test/groundtruth.csv',\n",
    "    'batch_size': 64,\n",
    "    'epochs': 10,\n",
    "    'lr': 5e-5,\n",
    "    'save_interval': 1000,\n",
    "    'log_interval': 100,\n",
    "    'save_dir': '../data/chexzero-experiments/',\n",
    "    'seed': 1234,\n",
    "    'optimizer': 'sgd',\n",
    "    'momentum': 0.9,\n",
    "    'context_length': 77,\n",
    "    'random_init': False,\n",
    "    'model_name': 'experiment_SMOKE_TEST'\n",
    "}\n",
    "\n",
    "config = Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f190579-0441-48ca-b12e-fc3d57e2428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_labels: List[str] = ['Atelectasis','Cardiomegaly', \n",
    "                                      'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "                                      'Lung Opacity', 'No Finding','Pleural Effusion', 'Pleural Other', 'Pneumonia', \n",
    "                                      'Pneumothorax', 'Support Devices']\n",
    "\n",
    "cxr_pair_template: Tuple[str] = (\"{}\", \"no {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "390f2fc5-8c34-434d-8341-03565bff795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_pipeline(\n",
    "    cxr_labels,\n",
    "    cxr_pair_template,\n",
    "    config\n",
    "): \n",
    "    model_save_dir = os.path.join(config.save_dir, config.model_name)\n",
    "    if not os.path.exists(model_save_dir): \n",
    "        # Create a new folder if not exists\n",
    "        os.makedirs(model_save_dir)\n",
    "    \n",
    "    # save config dictionary\n",
    "    config_path = os.path.join(model_save_dir, \"config.json\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config.__dict__, f)\n",
    "    \n",
    "    # create train objects\n",
    "    model, train_loaders, device, criterion, optimizer = train_make(config)\n",
    "    \n",
    "    # create validation objects\n",
    "    transformations = [\n",
    "        # means computed from sample in `cxr_stats` notebook\n",
    "        Normalize((101.48761, 101.48761, 101.48761), (83.43944, 83.43944, 83.43944)),\n",
    "    ]\n",
    "    input_resolution = 224\n",
    "    transformations.append(Resize(input_resolution, interpolation=InterpolationMode.BICUBIC))\n",
    "    transform = Compose(transformations)\n",
    "    val_dset = CXRTestDataset(img_path=config.val_cxr_filepath, transform=transform)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dset, shuffle=False)\n",
    "    \n",
    "    # Run training\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    report_freq = config.log_interval\n",
    "    best_roc_auc = -np.inf\n",
    "    \n",
    "    batch_train_losses = []\n",
    "    batch_val_roc_auc = []\n",
    "    y_true = make_true_labels(cxr_true_labels_path=config.val_groundtruth, cxr_labels=cxr_labels)\n",
    "    \n",
    "    for e, epoch in enumerate(range(config.epochs)):\n",
    "        running_loss = 0.0 # running loss over batch\n",
    "        \n",
    "        for train_loader in tqdm(train_loaders, desc='train_loader'):\n",
    "            for data in tqdm(train_loader, desc='batch'):\n",
    "                # get the images\n",
    "                images = data['img']\n",
    "\n",
    "                texts = data['txt']\n",
    "                texts = preprocess_text(texts, model) \n",
    "\n",
    "                # perform step for a single batch\n",
    "                loss = train_batch(images, texts, model, device, criterion, optimizer)\n",
    "                example_ct +=  len(images)\n",
    "                batch_ct += 1\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # save current batch's train loss\n",
    "                batch_train_losses.append(loss.item())\n",
    "                batch_train_losses_path = os.path.join(model_save_dir, \"batch_train_losses.json\")\n",
    "                with open(batch_train_losses_path, 'w') as f:\n",
    "                    json.dump(batch_train_losses, f)\n",
    "                \n",
    "                # perform validation after each batch\n",
    "                y_pred = run_softmax_eval(model, val_loader, cxr_labels, cxr_pair_template)\n",
    "                _, _, _, roc_auc = plot_roc(y_pred_i, y_true_i, roc_name)\n",
    "                \n",
    "                # save current batch's validation AUC\n",
    "                batch_val_roc_auc.append(roc_auc)\n",
    "                batch_val_roc_auc_path = os.path.join(model_save_dir, \"batch_val_roc_auc.json\")\n",
    "                with open(batch_val_roc_auc_path, 'w') as f:\n",
    "                    json.dump(batch_val_roc_auc, f)\n",
    "\n",
    "                # Report metrics every `report_freq` batch\n",
    "                if (batch_ct % report_freq) == 0:\n",
    "                    train_log(running_loss / report_freq, example_ct, epoch)\n",
    "                    running_loss = 0.0\n",
    "                \n",
    "                # save if AUC is higher than best-so-far\n",
    "                if roc_auc > best_roc_auc:\n",
    "                    checkpoint_name = f\"checkpoint_batch_{batch_ct}_batchsize_{config.batch_size}_auc_{roc_auc}.pt\"\n",
    "                    model_path = os.path.join(model_save_dir, checkpoint_name)\n",
    "                    print(\"Saved checkpoint to: \", model_path)\n",
    "                    save(model, model_path)\n",
    "                    best_roc_auc = roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f56ac910-1482-4f2c-b66a-1366c35fd5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n",
      "Interpolation Mode:  InterpolationMode.BICUBIC\n",
      "Finished image transforms for pretrained model.\n",
      "Loaded in pretrained model.\n",
      "Model on Device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loader:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/1 [00:13<?, ?it/s]\u001b[A\n",
      "train_loader:   0%|          | 0/10 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexperiment_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcxr_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcxr_pair_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 64\u001b[0m, in \u001b[0;36mexperiment_pipeline\u001b[0;34m(cxr_labels, cxr_pair_template, config)\u001b[0m\n\u001b[1;32m     61\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(batch_train_losses, f)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# perform validation after each batch\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mrun_softmax_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcxr_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcxr_pair_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m _, _, _, roc_auc \u001b[38;5;241m=\u001b[39m plot_roc(y_pred_i, y_true_i, roc_name)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# save current batch's validation AUC\u001b[39;00m\n",
      "File \u001b[0;32m~/CheXzero/notebooks/../zero_shot.py:253\u001b[0m, in \u001b[0;36mrun_softmax_eval\u001b[0;34m(model, loader, eval_labels, pair_template, context_length)\u001b[0m\n\u001b[1;32m    250\u001b[0m neg \u001b[38;5;241m=\u001b[39m pair_template[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# get pos and neg predictions, (num_samples, num_classes)\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m pos_pred \u001b[38;5;241m=\u001b[39m \u001b[43mrun_single_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msoftmax_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    255\u001b[0m neg_pred \u001b[38;5;241m=\u001b[39m run_single_prediction(eval_labels, neg, model, loader, \n\u001b[1;32m    256\u001b[0m                                  softmax_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, context_length\u001b[38;5;241m=\u001b[39mcontext_length) \n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# compute probabilities with softmax\u001b[39;00m\n",
      "File \u001b[0;32m~/CheXzero/notebooks/../zero_shot.py:196\u001b[0m, in \u001b[0;36mrun_single_prediction\u001b[0;34m(cxr_labels, template, model, loader, softmax_eval, context_length)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03mFUNCTION: run_single_prediction\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m--------------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03mReturns list, predictions from the given template. \u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m cxr_phrase \u001b[38;5;241m=\u001b[39m [template]\n\u001b[0;32m--> 196\u001b[0m zeroshot_weights \u001b[38;5;241m=\u001b[39m \u001b[43mzeroshot_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcxr_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcxr_phrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict(loader, model, zeroshot_weights, softmax_eval\u001b[38;5;241m=\u001b[39msoftmax_eval)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/CheXzero/notebooks/../zero_shot.py:114\u001b[0m, in \u001b[0;36mzeroshot_classifier\u001b[0;34m(classnames, templates, model, context_length)\u001b[0m\n\u001b[1;32m    112\u001b[0m zeroshot_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# compute embedding through model for each class\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassnames\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    115\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [template\u001b[38;5;241m.\u001b[39mformat(classname) \u001b[38;5;28;01mfor\u001b[39;00m template \u001b[38;5;129;01min\u001b[39;00m templates] \u001b[38;5;66;03m# format with class\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     texts \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mtokenize(texts, context_length\u001b[38;5;241m=\u001b[39mcontext_length) \u001b[38;5;66;03m# tokenize\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/env/lib/python3.12/site-packages/tqdm/notebook.py:233\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    232\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/env/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "experiment_pipeline(\n",
    "    cxr_labels,\n",
    "    cxr_pair_template,\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f257e30-3f3d-482c-8528-6f842b6c2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "        # means computed from sample in `cxr_stats` notebook\n",
    "        Normalize((101.48761, 101.48761, 101.48761), (83.43944, 83.43944, 83.43944)),\n",
    "    ]\n",
    "input_resolution = 224\n",
    "transformations.append(Resize(input_resolution, interpolation=InterpolationMode.BICUBIC))\n",
    "transform = Compose(transformations)\n",
    "val_dset = CXRTestDataset(img_path=config.val_cxr_filepath, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dset, shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4283d-d788-432b-a1a1-09bfb893e750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-env-env",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "env (Local)",
   "language": "python",
   "name": "conda-env-env-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
